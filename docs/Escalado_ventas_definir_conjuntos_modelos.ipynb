{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escalado con MinMaxScaler aplicado correctamente.\n",
      "Escalador guardado en: venta_pickles\\minmax_scaler.pkl\n",
      "Archivo CSV escalado guardado en: inmuebles_venta_procesado_escalado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Cargar el archivo CSV procesado de inmuebles en venta\n",
    "df = pd.read_csv('inmuebles_venta_procesado_clustering.csv')\n",
    "\n",
    "# Directorio para guardar los archivos pickle\n",
    "pickle_dir = 'venta_pickles'\n",
    "os.makedirs(pickle_dir, exist_ok=True)\n",
    "\n",
    "# Seleccionar las columnas numéricas que deseas escalar\n",
    "numeric_cols = ['Precio', 'Superficie Construida', 'Superficie Útil', 'CP_encoded']\n",
    "numeric_cols = [col for col in numeric_cols if col in df.columns]\n",
    "\n",
    "# Manejar valores faltantes (rellenar con la mediana)\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "# Instanciar MinMaxScaler para escalar al rango [0, 1]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Aplicar el escalado\n",
    "try:\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "    print(\"Escalado con MinMaxScaler aplicado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al aplicar el escalado: {e}\")\n",
    "\n",
    "# Guardar el objeto escalador en un archivo pickle si no existe\n",
    "scaler_path = os.path.join(pickle_dir, 'minmax_scaler.pkl')\n",
    "if not os.path.exists(scaler_path):\n",
    "    with open(scaler_path, 'wb') as file:\n",
    "        pickle.dump(scaler, file)\n",
    "    print(f\"Escalador guardado en: {scaler_path}\")\n",
    "else:\n",
    "    print(\"El archivo pickle ya existe. No se ha sobrescrito.\")\n",
    "\n",
    "# Guardar el DataFrame procesado y escalado\n",
    "output_csv_path = 'inmuebles_venta_procesado_escalado.csv'\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"Archivo CSV escalado guardado en: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificación de escalado con MinMaxScaler:\n",
      "Precio - Escalado correctamente: Mínimo: 0.00, Máximo: 1.00\n",
      "Superficie Construida - Escalado correctamente: Mínimo: 0.00, Máximo: 1.00\n",
      "Superficie Útil - Problema en el escalado: Mínimo: 0.00, Máximo: 1.00\n",
      "CP_encoded - Escalado correctamente: Mínimo: 0.00, Máximo: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Cargar el DataFrame procesado y escalado\n",
    "df_escalado = pd.read_csv('inmuebles_venta_procesado_escalado.csv')\n",
    "\n",
    "# Seleccionar las columnas numéricas escaladas\n",
    "numeric_cols = ['Precio', 'Superficie Construida', 'Superficie Útil', 'CP_encoded']\n",
    "numeric_cols = [col for col in numeric_cols if col in df_escalado.columns]\n",
    "\n",
    "# Verificación de escalado con MinMaxScaler\n",
    "print(\"\\nVerificación de escalado con MinMaxScaler:\")\n",
    "\n",
    "for col in numeric_cols:\n",
    "    try:\n",
    "        min_val = df_escalado[col].min()\n",
    "        max_val = df_escalado[col].max()\n",
    "\n",
    "        # Verificar si el rango es correcto\n",
    "        if min_val >= 0 and max_val <= 1:\n",
    "            print(f\"{col} - Escalado correctamente: Mínimo: {min_val:.2f}, Máximo: {max_val:.2f}\")\n",
    "        else:\n",
    "            print(f\"{col} - Problema en el escalado: Mínimo: {min_val:.2f}, Máximo: {max_val:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al verificar la columna {col}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir los conjuntos de Train y Test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de clasificación guardado como 'random_forest_classifier.pkl'.\n",
      "Accuracy: 0.9935518538420204\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1403\n",
      "           1       0.98      0.99      0.99       403\n",
      "           2       1.00      0.96      0.98        55\n",
      "\n",
      "    accuracy                           0.99      1861\n",
      "   macro avg       0.99      0.98      0.99      1861\n",
      "weighted avg       0.99      0.99      0.99      1861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Cargar el archivo escalado de inmuebles en venta\n",
    "df = pd.read_csv('inmuebles_venta_procesado_escalado.csv')\n",
    "\n",
    "# Definir las características (X) y la etiqueta (y)\n",
    "X = df.drop(columns=['cluster', 'Id']).select_dtypes(include=['float64', 'int64'])  # Solo columnas numéricas\n",
    "y = df['cluster']  # Etiqueta de los grupos de clustering\n",
    "\n",
    "# Verificar y manejar posibles valores faltantes (rellenar con la mediana solo para columnas numéricas)\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configurar y entrenar el modelo de clasificación\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Guardar el modelo entrenado en un archivo pickle\n",
    "with open('venta_pickles/random_forest_classifier.pkl', 'wb') as model_file:\n",
    "    pickle.dump(classifier, model_file)\n",
    "\n",
    "print(\"Modelo de clasificación guardado como 'random_forest_classifier.pkl'.\")\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define un modelo de clasificación que pueda clasificar un piso/casa a uno de los grupos creados por el algoritmo de clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del DataFrame: Index(['Id', 'Descripción', 'Localización', 'Enlace', 'Precio',\n",
      "       'Última Actualización', 'Timestamp_Scrapeo', 'Superficie Construida',\n",
      "       'Habitaciones', 'Baños', 'Antigüedad', 'Conservación',\n",
      "       'Superficie Útil', 'Tipo De Casa', 'CP', 'CP_encoded', 'Planta_11ª',\n",
      "       'Planta_12ª', 'Planta_13ª', 'Planta_14ª', 'Planta_15ª', 'Planta_16ª',\n",
      "       'Planta_17ª', 'Planta_1ª', 'Planta_2ª', 'Planta_3ª', 'Planta_4ª',\n",
      "       'Planta_5ª', 'Planta_6ª', 'Planta_7ª', 'Planta_8ª', 'Planta_9ª',\n",
      "       'Planta_Bajo', 'Planta_Entresuelo', 'Planta_Más de 20',\n",
      "       'Planta_No especificado', 'Planta_Principal', 'Planta_Semisótano',\n",
      "       'Planta_Sótano', 'cluster'],\n",
      "      dtype='object')\n",
      "Columnas seleccionadas para X (solo numéricas): Index(['Precio', 'Superficie Construida', 'Antigüedad', 'Conservación',\n",
      "       'Superficie Útil', 'Tipo De Casa', 'CP', 'CP_encoded', 'Planta_11ª',\n",
      "       'Planta_12ª', 'Planta_13ª', 'Planta_14ª', 'Planta_15ª', 'Planta_16ª',\n",
      "       'Planta_17ª', 'Planta_1ª', 'Planta_2ª', 'Planta_3ª', 'Planta_4ª',\n",
      "       'Planta_5ª', 'Planta_6ª', 'Planta_7ª', 'Planta_8ª', 'Planta_9ª',\n",
      "       'Planta_Bajo', 'Planta_Entresuelo', 'Planta_Más de 20',\n",
      "       'Planta_No especificado', 'Planta_Principal', 'Planta_Semisótano',\n",
      "       'Planta_Sótano'],\n",
      "      dtype='object')\n",
      "Accuracy: 0.9935518538420204\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1403\n",
      "           1       0.98      0.99      0.99       403\n",
      "           2       1.00      0.96      0.98        55\n",
      "\n",
      "    accuracy                           0.99      1861\n",
      "   macro avg       0.99      0.98      0.99      1861\n",
      "weighted avg       0.99      0.99      0.99      1861\n",
      "\n",
      "Modelo de clasificación guardado como 'modelo_clasificacion_clusters.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "\n",
    "# Cargar el archivo escalado\n",
    "df = pd.read_csv('inmuebles_venta_procesado_escalado.csv')\n",
    "\n",
    "# Verificar las columnas presentes en el DataFrame\n",
    "print(\"Columnas del DataFrame:\", df.columns)\n",
    "\n",
    "# Definir las características (X) y la etiqueta (y)\n",
    "# Asegurarnos de seleccionar solo columnas numéricas\n",
    "X = df.select_dtypes(include=['float64', 'int64']).drop(columns=['cluster', 'Id'], errors='ignore')\n",
    "y = df['cluster']\n",
    "\n",
    "# Verificar las columnas seleccionadas para X\n",
    "print(\"Columnas seleccionadas para X (solo numéricas):\", X.columns)\n",
    "\n",
    "# Verificar y manejar posibles valores faltantes\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configurar y entrenar el modelo de clasificación\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Guardar el modelo entrenado en un archivo pickle\n",
    "with open('venta_pickles/modelo_clasificacion_clusters.pkl', 'wb') as model_file:\n",
    "    pickle.dump(classifier, model_file)\n",
    "\n",
    "print(\"Modelo de clasificación guardado como 'modelo_clasificacion_clusters.pkl'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
